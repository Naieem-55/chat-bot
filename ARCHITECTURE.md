# ğŸ¤– RAG Customer Support Chatbot - System Architecture

## ğŸ“‹ Overview

This is a **RAG (Retrieval Augmented Generation)** chatbot system that combines:
- **Document retrieval** from a vector database
- **LLM generation** using free models (Groq API with Llama 3.1)
- **Conversation management** with session history
- **Smart features** like autocomplete, suggestions, and hallucination detection

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND (Port 3001)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ index.html â”‚  â”‚  chat.js     â”‚  â”‚  suggestions.js        â”‚  â”‚
â”‚  â”‚            â”‚  â”‚  (v3.4)      â”‚  â”‚  (autocomplete, PAA)   â”‚  â”‚
â”‚  â”‚  - UI      â”‚  â”‚  - Messages  â”‚  â”‚  - Smart suggestions   â”‚  â”‚
â”‚  â”‚  - Input   â”‚  â”‚  - API calls â”‚  â”‚  - Follow-ups          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                         HTTP/JSON
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND API (Port 8000)                       â”‚
â”‚                         FastAPI Server                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  main.py - API Endpoints:                                â”‚   â”‚
â”‚  â”‚  â€¢ POST /session/create    - Create session              â”‚   â”‚
â”‚  â”‚  â€¢ POST /chat              - Send message                â”‚   â”‚
â”‚  â”‚  â€¢ POST /feedback          - Submit feedback             â”‚   â”‚
â”‚  â”‚  â€¢ GET  /suggestions/*     - Get suggestions             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RAG PIPELINE CORE                           â”‚
â”‚                      (rag_pipeline.py)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚                â”‚
          â–¼                â–¼                â–¼                â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Session    â”‚ â”‚    Query     â”‚ â”‚   Document   â”‚ â”‚   LLM    â”‚
  â”‚   Manager    â”‚ â”‚Reformulator  â”‚ â”‚  Retriever   â”‚ â”‚  Client  â”‚
  â”‚              â”‚ â”‚              â”‚ â”‚              â”‚ â”‚          â”‚
  â”‚ - History    â”‚ â”‚ - Context    â”‚ â”‚ - Vector     â”‚ â”‚ - Groq   â”‚
  â”‚ - Context    â”‚ â”‚ - Improve    â”‚ â”‚ - BM25       â”‚ â”‚   API    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ - Hybrid     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚  Vector Store    â”‚
                                  â”‚   (FAISS DB)     â”‚
                                  â”‚                  â”‚
                                  â”‚ - Embeddings     â”‚
                                  â”‚ - Documents      â”‚
                                  â”‚ - Metadata       â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Message Flow (Step-by-Step)

### **1ï¸âƒ£ User Sends a Message**

```
User types: "What is your return policy?"
           â†“
    [Send Button Click]
           â†“
    chat.js: sendMessage()
           â†“
    POST /chat â†’ Backend API
```

**File**: `frontend/chat.js:499-691`

---

### **2ï¸âƒ£ Backend Receives Request**

```
FastAPI: /chat endpoint
           â†“
    Validate request
           â†“
    Get/Create session_id
           â†“
    Call RAG Pipeline
```

**File**: `src/api/main.py:179-243`

---

### **3ï¸âƒ£ RAG Pipeline Processing**

```
rag_pipeline.process_query()
           â”‚
           â”œâ”€â–º Step 1: Get conversation history
           â”‚   SessionManager â†’ Retrieve past messages
           â”‚
           â”œâ”€â–º Step 2: Reformulate query (if needed)
           â”‚   QueryReformulator â†’ Improve question clarity
           â”‚   "return policy" â†’ "What is the return and refund policy?"
           â”‚
           â”œâ”€â–º Step 3: Hybrid Document Retrieval
           â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   â”‚ Vector Search (semantic)   50%   â”‚
           â”‚   â”‚ BM25 Search (keyword)      30%   â”‚
           â”‚   â”‚ Reformulated Query         20%   â”‚
           â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚   â†’ Retrieve top 5 most relevant documents
           â”‚
           â”œâ”€â–º Step 4: Format context
           â”‚   Combine retrieved documents into text
           â”‚
           â”œâ”€â–º Step 5: Build LLM prompt
           â”‚   System Prompt + History + Context + User Query
           â”‚
           â”œâ”€â–º Step 6: Generate response
           â”‚   LLM Client â†’ Groq API (Llama 3.1)
           â”‚   â†’ "Our return policy allows returns within 30 days..."
           â”‚
           â”œâ”€â–º Step 7: Save to history
           â”‚   SessionManager â†’ Store user query + bot response
           â”‚
           â””â”€â–º Step 8: Return response with metadata
               {
                 "response": "Our return policy...",
                 "sources": [{...}],
                 "session_id": "abc123",
                 "context_used": true
               }
```

**File**: `src/rag_pipeline.py:67-151`

---

### **4ï¸âƒ£ Response Enhancement**

```
API adds extra features:
           â”‚
           â”œâ”€â–º Hallucination Detection
           â”‚   Check if response is grounded in sources
           â”‚   Risk level: Low/Medium/High
           â”‚
           â”œâ”€â–º Generate message_id
           â”‚   UUID for feedback tracking
           â”‚
           â””â”€â–º Return ChatResponse
```

**File**: `src/api/main.py:216-236`

---

### **5ï¸âƒ£ Frontend Displays Response**

```
chat.js receives response
           â”‚
           â”œâ”€â–º Remove loading spinner
           â”‚
           â”œâ”€â–º Stream text with typing effect
           â”‚   Character-by-character animation
           â”‚
           â”œâ”€â–º Add sources (ğŸ“š section)
           â”‚   Show relevant documents used
           â”‚
           â”œâ”€â–º Add feedback buttons (ğŸ‘ ğŸ‘)
           â”‚
           â”œâ”€â–º Show "People Also Asked"
           â”‚   Generate related follow-up questions
           â”‚
           â””â”€â–º Re-enable input field
```

**File**: `frontend/chat.js:543-672`

---

## ğŸ§© Key Components Explained

### **ğŸ“¦ Vector Store (FAISS)**
**Location**: `src/vector_store/faiss_store.py`

- Stores document embeddings (768-dimensional vectors)
- Uses `sentence-transformers/all-MiniLM-L6-v2` model
- Fast similarity search (IndexFlatL2)
- Currently has **125 documents** loaded

**How it works**:
```python
User Query: "refund"
    â†“
Embedding Model â†’ [0.24, -0.18, 0.91, ...] (768 numbers)
    â†“
FAISS Search â†’ Find similar document vectors
    â†“
Return top 5 matching documents
```

---

### **ğŸ” Hybrid Retrieval**
**Location**: `src/retrieval/retriever.py`, `src/retrieval/bm25_retriever.py`

Combines 3 search methods:

| Method | Type | Weight | Purpose |
|--------|------|--------|---------|
| **Vector Search** | Semantic | 50% | Understands meaning |
| **BM25 Search** | Keyword | 30% | Exact word matching |
| **Reformulated Query** | Enhanced | 20% | Improved question |

**Example**:
```
User: "can I return"
Vector Search â†’ Finds "return policy", "refund guidelines"
BM25 Search   â†’ Finds exact word "return" in docs
Reformulated  â†’ "What is the return policy?" (clearer)
```

---

### **ğŸ§  LLM Client (Groq API)**
**Location**: `src/llm/huggingface_client.py`

- **Model**: `llama-3.1-8b-instant` (FREE tier)
- **API**: Groq (70k tokens/day free)
- **Speed**: Ultra-fast inference
- **Cost**: $0 (completely free)

**Prompt Template**:
```
System: You are a helpful customer support assistant...

Context from Documents:
---
[Retrieved document 1]
[Retrieved document 2]
...
---

User: What is your return policy?